## **多跳查询的原理与作用**

#### **一、 原理 (The "How")**

想象一下一个侦探在办案，他不会指望通过一次询问就解决所有问题。他会：
1.  **第一跳 (Hop 1)**: 询问目击者A，得到一条线索（“嫌疑人往东边跑了”）
2.  **第二跳 (Hop 2)**: 基于第一条线索，他去东边的街区调取监控，发现嫌疑人上了一辆特定牌照的车
3.  **第三跳 (Hop 3)**: 基于第二条线索，他去车管所查询车牌，找到了车主信息
4.  **最终综合**: 将所有线索串联起来，形成完整的证据链，锁定嫌疑人

**多跳查询就是 Agent 模仿这个过程。** 它不是试图用一个大而复杂的问题去暴力检索，而是：

1.  **分解 (Decomposition)**: Agent (在LLM的驱动下) 首先分析用户的复杂问题（例如：“写出《三体》这本书的作者，并介绍一下他的另一部知名作品”），并将其分解成一系列更小、更具体的子问题
    *   子问题1: “《三体》的作者是谁？”
    *   子问题2: “刘慈欣除了《三体》外，还有哪些知名作品？”

2.  **迭代执行 (Iterative Execution)**: Agent 逐一执行这些子问题
    *   **第一跳**: Agent 执行“子问题1”，调用知识库工具查询，得到结果：“刘慈欣”
    *   **第二跳**: Agent 将第一跳的结果“刘慈欣”作为上下文，来执行“子问题2”，再次调用知识库，得到结果：“《流浪地球》”

3.  **综合 (Synthesis)**: Agent 将所有中间步骤获得的信息片段整合起来，生成一个连贯、全面的最终答案，回答用户最初的复杂问题

#### **二、 作用 (The "Why")**

引入多跳查询将为我们的 Agent 带来质的飞跃：

1.  **解决复杂关联问题**: 这是其最核心的作用。对于那些需要将不同信息点关联起来才能回答的问题，单次检索往往无能为力，而多跳查询则游刃有余

2.  **大幅提升检索准确率**: 一个长而复杂的查询问题，其生成的 embedding（向量）往往是“模糊”和“平均”的，很难在向量空间中精确匹配到任何一个具体的知识片段。而分解后的短、具体的子问题，其 embedding 更加“尖锐”，能够更精准地命中目标文档，从而提高 RAG 的整体效果

3.  **增强推理的透明度**: 我们可以清晰地看到 Agent 的“思考链”。日志不再是“输入 -> 输出”，而是“输入 -> 思考与分解 -> 执行步骤1 -> 获得信息1 -> 思考下一步 -> 执行步骤2 -> 获得信息2 -> ... -> 综合答案”。这使得 Agent 的行为不再是一个黑箱，极大地便利了调试和优化

4.  **模拟人类解决问题的范式**: 这种分解、探索、综合的模式更接近人类的自然思维方式，使得 Agent 的表现更加智能和强大，能够处理更开放、更具挑战性的任务

---

### **多跳查询开发文档 (Development Plan)**

好的，项目经理。我们已经理解了多跳查询的价值。现在，这是我们给 Claude（开发工程师）的详细开发文档，指导他如何实现这个功能

**任务名称：开发多跳查询推理 Agent (Multi-Hop Query Agent)**

**目标：** 演进我们现有的 ReAct Agent，使其具备多跳查询能力。新的 Agent 能够将复杂问题分解为一系列简单的、可执行的子查询，并综合各步骤的结果来生成最终答案

**项目经理最终验收标准：**
1.  Agent 能够在一个新的图定义文件 (`graphs/multi_hop_graph.py`) 中实现
2.  面对复杂问题，Agent 的日志清晰地展示出分解、多步工具调用和最终综合的过程
3.  面对简单问题，Agent 应能直接回答或进行单次工具调用，而不是强制进行不必要的多跳分解
4.  新的 Agent 可以通过工厂 (`agent_factory.py`) 被创建，与基础 Agent 并存

---

#### **实现步骤逻辑 (Work Breakdown & Instructions for Claude)**

##### **第一阶段：核心驱动力——提示工程 (Prompt Engineering)**

这是实现多跳推理的灵魂。我们需要设计一个新的系统提示 (System Prompt)，教会 LLM 如何进行分解和思考

*   **任务 1.1: 设计多跳推理的系统提示**
    *   **指令**: Claude，你需要创建一个新的、更强大的系统提示。这个提示必须明确地指导 LLM：
        1.  **角色定义**: “你是一个善于解决复杂问题的专家级研究员”
        2.  **分解指令**: “当面对一个复杂问题时，你的首要任务是将其分解成一个有序的、逻辑清晰的子问题列表。你的思考过程应该被展示出来”
        3.  **迭代执行指令**: “你应该逐一解决这些子问题。利用前一个子问题的答案来帮助你构建下一个子问题的查询”
        4.  **终止条件**: “当你判断已经收集了足够的信息来完整地回答原始问题时，你应该停止调用工具，并输出最终的综合性答案”
        5.  **格式要求**: “你的思考过程和计划应该在每次决策时被清晰地表述出来”

##### **第二阶段：架构演进——修改图与状态 (可选但推荐)**

为了更好地管理多跳流程，我们可以对 `AgentState` 和图结构进行微调

*   **任务 2.1: (可选) 演进 `AgentState`**
    *   **指令**: Claude，为了让多跳的状态更清晰，请考虑在 `core/agent_state.py` 的 `AgentState` 中增加一个新字段，例如：
        *   `plan: List[str]`：用于存储 LLM 生成的子问题计划
        *   `original_query: str`：始终保存用户最原始的那个问题
    *   **说明**: 这一步不是强制的。一个足够智能的 LLM 也可以通过不断回顾 `messages` 历史来管理自己的状态。但显式地管理状态会让逻辑更清晰、更可控

*   **任务 2.2: 设计新的图结构 (`graphs/multi_hop_graph.py`)**
    *   **指令**: Claude，请创建一个新文件 `graphs/multi_hop_graph.py`。你可以复制 `base_agent_graph.py` 的结构作为起点
    *   **核心修改**:
        1.  **引入“规划”节点 (Planner Node)**：你可以创建一个新的节点，专门负责接收用户问题并生成查询计划（即填充 `AgentState` 中的 `plan` 字段）
        2.  **修改“执行”节点 (Executor Node)**：原有的 `agent_node` 现在可以被看作是“执行者”。它不再思考整个问题，而是从 `plan` 中取出当前的子问题来执行
        3.  **修改路由逻辑**: 条件路由 `should_continue` 现在需要判断“计划是否已经执行完毕”。如果计划列表为空，则进入“综合答案”节点；否则，继续执行下一个子问题
        4.  **引入“综合”节点 (Synthesizer Node)**：这是一个新的、最终的节点。它接收完整的 `messages` 历史（包含了所有跳的问答结果），并基于此生成最终答案

##### **第三阶段：集成与测试**

*   **任务 3.1: 更新 `agent_factory.py`**
    *   **指令**: Claude，请在 `agent_factory.py` 中创建一个新的工厂函数，例如 `get_multi_hop_agent_runnable()`。这个函数将负责导入和编译 `multi_hop_graph.py` 中定义的图，使其可以被项目其他部分调用

*   **任务 3.2: 编写测试用例**
    *   **指令**: Claude，请准备一组新的测试问题，用于验证多跳查询的能力
        *   **简单问题 (预期单跳)**: “LangGraph 是什么？”
        *   **中等复杂问题 (预期2跳)**: “ChromaDB 的主要功能是什么？它和 FAISS 有什么区别？”
        *   **高级复杂问题 (预期3跳或更多)**: “请总结一下实现 RAG 系统中‘查询扩展’和‘重排序’这两种优化技术的原理，并分析它们的优缺点”

---
**交付与审查**

*   **指令**: Claude，请按照上述文档完成开发。在交付时，请提供 `run.py` 使用一个复杂问题进行测试的完整日志流。我们需要在日志中清晰地看到问题分解、多步工具调用、以及最终答案的生成过程

项目经理，这份开发文档为 Claude 提供了清晰的实现路径和明确的交付标准。我们可以开始了