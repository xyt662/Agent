# 1. Similarity Search (相似性搜索)
实现原理：

这是最基础最核心的向量检索方式，其原理是：将用户的 query 也转化为一个向量 (查询向量)，然后在向量数据库中计算这个查询向量与所有文档块向量之间的“距离”或“相似度” (通常使用余弦相似度)。最后返回与查询向量“距离”最近的 k 个文档

适用场景：

适用于绝大多数标准的问答场景。当用户提出一个具体问题，你希望找到最直接、最相关的答案时，就使用它

## 准备工作：获取基础数据

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Tuple
from langchain_core.documents import Document

# 假设已经有一个 VectorDBRetriever 的实例
# from your_project.retrieval.base_retriever import VectorDBRetriever
# db_retriever = VectorDBRetriever()

# ---
# 1.获取 ChromaDB 实例
vectorstore = db_retriever.get_vectorstore()

# 2.获取所有文档和元数据(这会加载整个集合)
db_contents = vectorstore.get()
all_docs_content = db_contents['documents']
all_docs_metadata = db_contents['metadatas']
all_vectors = np.array(db_contents['embeddings'])   # 将向量转化为Numpy数组

# 3.将内容和元数据重新组合成LangChain Document对象
all_docs = [
    Document(page_content=content, metadata=metadata)
    for conntent, metadata in zip(all_docs_content, all_docs_metadata)
]

# 4.获取嵌入数据
embedding_function = db_retriever.vectorstore.embedding_function
print(f"准备工作完成！已加载{len(all_docs)}个文档及向量")
```

## Similarity Search 的原理实现
```python
def manual_similarity_search(
        query_text: str,
        k: int
) -> List[Tuple[Document, float]]:
    """
    手动实现基础的相似性搜索
    
    Args:
        query_text:用户的查询
        k:要返回的文档数量
        
    Returns:
        一个元组列表，每个元组包含(文档，相似性分数)
    """
    # 1.将查询文本转化为向量
    query_vector = embedding_function.embed_query(query_text)
    query_vector_reshaped = np.array(query_vector).reshape(1, -1)

    # 2.计算查询向量与所有文档向量的余弦相似度
    # cosine_similarity 会返回一个二维数组，如[[0.8, 0.2, 0.9]]，我们取第一行
    scroes = cosine_similarity(query_vector_reshaped, all_vectors)[0]

    # 3.将文档、分数和索引配对
    result_with_scores = list(zip(all_docs, scroes))

    # 4.按分数从高到低排序
    sorted_result = sorted(result_with_scores, key=lambda item: item[1], reverse=True)

    # 5.返回前k个结果
    return sorted_result[:k]
```
# 2.Similarity Score Threshold (相似性分数阈值)
实验原理：

这是一种基于质量过滤的检索策略，它在进行相似性搜索后，增加了一个额外的过滤步骤：只返回那些相似度分数高于某个设定预制的文档。如果相似性的文档分数都达不到这个门槛，它可能会只返回一个空列表

适用场景：

此策略对于避免 Agent 的幻觉 (**Hallucination**) 至关重要。如果知识库中没有与用户问题相关的内容，强行返回一些低质量、不相关的文档块，反而会误导大语言模型。使用阈值可以确保只有在找到高质量信息时才提供给 LLM

## Similarity Score Threshold 的原理实现
```
def manual_threshold_search(
    query_text: str, k: int, threshold: float
) -> List[Tuple[Document, float]]:
    """
    手动实现带分数阈值的相似性搜索

    Args:
        query_text:用户的查询
        k:要返回的文档数量
        threshold:相似度分数的最小阈值

    Returns:
        一个元组列表，每个元组包含(文档，相似性分数)
    """
    # 1.先执行完整的相似性搜索
    all_search_results = manual_similarity_search(query_text, k=k)
    all_sorted_results = manual_similarity_search(query_text, k=len(all_docs))

    # 2. 增加过滤步骤：只保留分数高于阈值的文档
    filtered_results = [
        (doc, score) for doc, score in all_sorted_results if score >= score_threshold
    ]

    # 3. 从过滤后的结果中返回前 k 个
    return filtered_results[:k]
```
# 3.Maximal Marginal Relevance (MMR, 最大边际相关性)
实现原理：

MMR 试图在“相关性”和“多样性”之间取得平衡，它分两步工作：

1. 首先像相似性搜索一样，找出与查询最相关的一批文档
2. 然后从这批文档中取出最终的 k 个，挑选的规则是：第一个选取最相关的；第二个选与查询相关，但与第一个已选文档最不相似的；第三个选与查询相关，但与前两个已选文档都最不相似的，以此类推。它不仅要文档与查询相关，还要文档之间互相不要太相似，从而提供更多样化的信息

适用场景：

当用户的查询比较宽泛，可能涉及多个方面时，MMR 非常有用。例如，用户问“介绍一下 RAG-Agent 项目”，你可能不希望返回 5 个都在说“它用了 FastAPI”的文档，而是希望返回的文档分别介绍架构、工具、部署等不同方面

## Maximal Marginal Relevance 的原理实现
```
def manual_mmr_search(
        query_text: str, k: int, fetch_k: int, lambda_mult: float
) -> List[Document]:
    """
    手动实现MMR搜索

    Args:
        query_text:用户的查询
        k:最终要返回的文档数量
        fetch_k:初始候选池的大小
        lambda_mult:用于平衡相关性和多样性的因子(0-1)

    Returns:
        一个文档列表
    """
    if k > fetch_k:
        raise ValueError("k 必须小于或等于 fetch_k")

    # 1.获取初始的、最相关的候选文档池
    candidates_with_scores = manual_similarity_search(query_text, k=fetch_k)

    if not candidates_with_scores:
        return []  # 如果初始搜索就没有结果，直接返回空列表

    # 获取候选文档的索引，以便于查找它们的向量
    candidate_indices = [all_docs.index(doc) for doc, score in candidates_with_scores]
    candidate_vectors = all_vectors[candidate_indices]

    # 2.选出最相关文档作为第一个结果
    best_candidate_index = candidate_indices[0]
    results_indices = [best_candidate_index]
    candidate_indices.pop(0)

    # 3.迭代k-1次来填充剩下的结果
    while len(results_indices) < k and len(candidate_indices) > 0:
        mmr_scores = {}

        # 获取已选结果的向量
        selected_vectors = all_vectors[results_indices]

        # 遍历所有剩下的候选者
        for idx in candidate_indices:
            candidate_vector = all_vectors[idx].reshape(1, -1)

            # 计算与查询的相关性
            query_similarity = next(
                score
                for doc, score in candidates_with_scores
                if all_docs.index(doc) == idx
            )

            # 计算与已选结果的最大相似度(即多样性惩罚)
            redundancy_scores = cosine_similarity(candidate_vector, selected_vectors)[0]
            max_redunancy = np.max(redundancy_scores)

            # 计算MMR分数
            mmr_score = (
                    lambda_mult * query_similarity - (1 - lambda_mult) * max_redunancy
            )
            mmr_scores[idx] = mmr_score

        if not mmr_scores:
            break

        # 选出MMR分数最高的候选者
        next_best_idx = max(mmr_scores, key=mmr_scores.get)

        # 添加到结构并从候选者中移除
        results_indices.append(next_best_idx)
        candidate_indices.remove(next_best_idx)

    # 4.根据最终的索引列表返回文档
    return [all_docs[i] for i in results_indices]
```