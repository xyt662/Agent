"""äº‹ä»¶é©±åŠ¨AgentStateä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªæ–‡ä»¶æ¼”ç¤ºäº†å¦‚ä½•åœ¨LangGraphèŠ‚ç‚¹ä¸­ä½¿ç”¨æ–°çš„äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œ
åŒ…æ‹¬è‡ªæˆ‘çº é”™ã€é•¿æœŸè®°å¿†ã€å¤šæ™ºèƒ½ä½“åä½œç­‰é«˜çº§åŠŸèƒ½çš„å®ç°
"""

import uuid
from datetime import datetime
from typing import Dict, Any, List

from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from src.rag_agent.core.agent_state import AgentState, EventType, EventStatus
from src.rag_agent.core.state_aggregator import StateAggregator
from src.rag_agent.core.event_utils import EventMessageFactory, EventQueryHelper


def example_self_correction_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šè‡ªæˆ‘çº é”™èŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•æ£€æµ‹é”™è¯¯å¹¶è§¦å‘è‡ªæˆ‘çº é”™æœºåˆ¶
    """
    messages = state["messages"]
    new_messages = []
    
    # 1. æ£€æŸ¥æœ€è¿‘çš„å·¥å…·æ‰§è¡Œæ˜¯å¦å¤±è´¥
    recent_tool_messages = [msg for msg in messages[-5:] if isinstance(msg, ToolMessage)]
    
    for tool_msg in recent_tool_messages:
        if "error" in tool_msg.content.lower() or "failed" in tool_msg.content.lower():
            # è§¦å‘çº é”™äº‹ä»¶
            correction_event = EventMessageFactory.create_correction_trigger_event(
                reason=f"å·¥å…·æ‰§è¡Œå¤±è´¥: {getattr(tool_msg, 'name', 'unknown')}",
                error_type="tool_failure",
                context={"tool_content": tool_msg.content}
            )
            new_messages.append(correction_event)
            
            # åˆ›å»ºçº é”™å°è¯•
            correction_attempt = EventMessageFactory.create_correction_attempt_event(
                correction_action="é‡æ–°åˆ†æé—®é¢˜å¹¶é€‰æ‹©åˆé€‚çš„å·¥å…·",
                parent_event_id=correction_event.additional_kwargs["metadata"]["event_id"]
            )
            new_messages.append(correction_attempt)
    
    return {"messages": messages + new_messages}


def example_memory_management_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šè®°å¿†ç®¡ç†èŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•å­˜å‚¨å’Œæ£€ç´¢é•¿æœŸè®°å¿†
    """
    messages = state["messages"]
    new_messages = []
    
    # 1. æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦ä¿¡æ¯éœ€è¦å­˜å‚¨
    if messages:
        last_message = messages[-1]
        if isinstance(last_message, AIMessage) and "é‡è¦" in last_message.content:
            # å­˜å‚¨é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†
            memory_key = f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            memory_event = EventMessageFactory.create_memory_store_event(
                memory_key=memory_key,
                content=last_message.content,
                context={"importance_level": "high"}
            )
            new_messages.append(memory_event)
    
    # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦æ£€ç´¢è®°å¿†
    if messages and isinstance(messages[-1], HumanMessage):
        user_message = messages[-1].content
        if any(keyword in user_message for keyword in ["ä¹‹å‰", "å†å²", "è®°å¾—"]):
            # æ£€ç´¢ç›¸å…³è®°å¿†
            retrieval_event = EventMessageFactory.create_memory_retrieve_event(
                query_context=user_message[:100],
                context={"retrieval_trigger": "user_reference"}
            )
            new_messages.append(retrieval_event)
    
    return {"messages": messages + new_messages}


def example_multi_agent_collaboration_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šå¤šæ™ºèƒ½ä½“åä½œèŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•å§”æ´¾ä»»åŠ¡ç»™å…¶ä»–æ™ºèƒ½ä½“
    """
    messages = state["messages"]
    new_messages = []
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦å§”æ´¾ä»»åŠ¡
    if messages and isinstance(messages[-1], HumanMessage):
        user_message = messages[-1].content
        
        # ç®€å•çš„ä»»åŠ¡åˆ†ç±»é€»è¾‘
        if "ç¿»è¯‘" in user_message:
            # å§”æ´¾ç»™ç¿»è¯‘ä¸“å®¶
            delegation_event = EventMessageFactory.create_agent_delegation_event(
                target_agent="translation_expert",
                task_description=f"ç¿»è¯‘ä»»åŠ¡: {user_message}",
                context={"task_type": "translation", "priority": "normal"}
            )
            new_messages.append(delegation_event)
            
        elif "æ•°æ®åˆ†æ" in user_message:
            # å§”æ´¾ç»™æ•°æ®åˆ†æä¸“å®¶
            delegation_event = EventMessageFactory.create_agent_delegation_event(
                target_agent="data_analyst",
                task_description=f"æ•°æ®åˆ†æä»»åŠ¡: {user_message}",
                context={"task_type": "analysis", "priority": "high"}
            )
            new_messages.append(delegation_event)
    
    return {"messages": messages + new_messages}


def example_clarification_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šä¸»åŠ¨æ¾„æ¸…èŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•æ£€æµ‹æ­§ä¹‰å¹¶è¯·æ±‚æ¾„æ¸…
    """
    messages = state["messages"]
    new_messages = []
    
    if messages and isinstance(messages[-1], HumanMessage):
        user_message = messages[-1].content
        
        # æ£€æµ‹æ­§ä¹‰çš„ç®€å•è§„åˆ™
        ambiguous_keywords = ["è¿™ä¸ª", "é‚£ä¸ª", "å®ƒ", "ä»–ä»¬"]
        if any(keyword in user_message for keyword in ambiguous_keywords):
            # è¯·æ±‚æ¾„æ¸…
            clarification_event = EventMessageFactory.create_clarification_request_event(
                question="æ‚¨æåˆ°çš„'è¿™ä¸ª'å…·ä½“æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿèƒ½å¦æä¾›æ›´å¤šç»†èŠ‚ï¼Ÿ",
                context={"ambiguous_terms": ambiguous_keywords, "original_message": user_message}
            )
            new_messages.append(clarification_event)
    
    return {"messages": messages + new_messages}


def example_multi_hop_query_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šå¤šè·³æŸ¥è¯¢èŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•å¤„ç†å¤æ‚çš„å¤šæ­¥éª¤æŸ¥è¯¢
    """
    messages = state["messages"]
    new_messages = []
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ‚æŸ¥è¯¢
    if messages and isinstance(messages[-1], HumanMessage):
        user_message = messages[-1].content
        
        # æ£€æµ‹å¤æ‚æŸ¥è¯¢çš„å…³é”®è¯
        complex_indicators = ["é¦–å…ˆ", "ç„¶å", "æ¥ä¸‹æ¥", "æœ€å", "æ­¥éª¤"]
        if any(indicator in user_message for indicator in complex_indicators):
            # å¼€å§‹å¤šè·³æŸ¥è¯¢
            query_id = str(uuid.uuid4())
            
            # ç¬¬ä¸€æ­¥
            step1_event = EventMessageFactory.create_multi_hop_step_event(
                hop_index=1,
                step_description="åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œè¯†åˆ«æŸ¥è¯¢æ­¥éª¤",
                parent_event_id=query_id,
                context={"original_query": user_message}
            )
            new_messages.append(step1_event)
            
            # ç¬¬äºŒæ­¥
            step2_event = EventMessageFactory.create_multi_hop_step_event(
                hop_index=2,
                step_description="æ‰§è¡Œç¬¬ä¸€ä¸ªå­æŸ¥è¯¢",
                parent_event_id=query_id,
                context={"sub_query": "æå–å…³é”®ä¿¡æ¯"}
            )
            new_messages.append(step2_event)
    
    return {"messages": messages + new_messages}


def example_state_analysis_node(state: AgentState) -> AgentState:
    """
    ç¤ºä¾‹ï¼šçŠ¶æ€åˆ†æèŠ‚ç‚¹
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨StateAggregatoråˆ†æå½“å‰çŠ¶æ€
    """
    messages = state["messages"]
    new_messages = []
    
    # è·å–ç»¼åˆçŠ¶æ€
    comprehensive_state = StateAggregator.get_comprehensive_state(messages)
    
    # åˆ†æçŠ¶æ€å¹¶ç”ŸæˆæŠ¥å‘Š
    analysis_parts = []
    
    # è®°å¿†çŠ¶æ€åˆ†æ
    memory_state = comprehensive_state['memory']
    if memory_state['stored_memories']:
        analysis_parts.append(f"é•¿æœŸè®°å¿†: {len(memory_state['stored_memories'])}æ¡è®°å½•")
    
    # çº é”™çŠ¶æ€åˆ†æ
    correction_state = comprehensive_state['correction']
    if correction_state['active_corrections']:
        analysis_parts.append(f"æ´»è·ƒçº é”™: {len(correction_state['active_corrections'])}ä¸ªä»»åŠ¡")
    
    # åä½œçŠ¶æ€åˆ†æ
    collaboration_state = comprehensive_state['collaboration']
    if collaboration_state['active_delegations']:
        analysis_parts.append(f"åä½œä»»åŠ¡: {len(collaboration_state['active_delegations'])}ä¸ªå§”æ´¾")
    
    if analysis_parts:
        # ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
        report_content = f"ğŸ“Š å½“å‰çŠ¶æ€: {'; '.join(analysis_parts)}"
        system_event = EventMessageFactory.create_system_event(
            content=report_content,
            context={"state_analysis": comprehensive_state}
        )
        new_messages.append(system_event)
    
    return {"messages": messages + new_messages}


def example_event_query_usage(messages: List):
    """
    ç¤ºä¾‹ï¼šäº‹ä»¶æŸ¥è¯¢åŠŸèƒ½çš„ä½¿ç”¨
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨EventQueryHelperæŸ¥è¯¢ç‰¹å®šäº‹ä»¶
    """
    # æŸ¥æ‰¾æ‰€æœ‰è®°å¿†ç›¸å…³äº‹ä»¶
    memory_events = EventQueryHelper.find_events_by_type(messages, EventType.MEMORY_STORE)
    print(f"æ‰¾åˆ° {len(memory_events)} ä¸ªè®°å¿†å­˜å‚¨äº‹ä»¶")
    
    # æŸ¥æ‰¾æ‰€æœ‰å¾…å¤„ç†çš„äº‹ä»¶
    pending_events = EventQueryHelper.find_events_by_status(messages, EventStatus.PENDING)
    print(f"æ‰¾åˆ° {len(pending_events)} ä¸ªå¾…å¤„ç†äº‹ä»¶")
    
    # æŸ¥æ‰¾æœ€æ–°çš„çº é”™äº‹ä»¶
    latest_correction = EventQueryHelper.get_latest_event_by_type(messages, EventType.CORRECTION_TRIGGER)
    if latest_correction:
        print(f"æœ€æ–°çº é”™äº‹ä»¶: {latest_correction.content}")
    
    # æŸ¥æ‰¾äº‹ä»¶é“¾
    if memory_events:
        first_memory_event = memory_events[0]
        event_id = first_memory_event.additional_kwargs["metadata"]["event_id"]
        related_events = EventQueryHelper.find_event_chain(messages, event_id)
        print(f"æ‰¾åˆ° {len(related_events)} ä¸ªç›¸å…³äº‹ä»¶")


def create_sample_conversation() -> List:
    """
    åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å¯¹è¯ï¼Œå±•ç¤ºäº‹ä»¶é©±åŠ¨æ¶æ„çš„å®Œæ•´æµç¨‹
    """
    messages = []
    
    # 1. ç”¨æˆ·æé—®
    messages.append(HumanMessage(content="è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªæ•°æ®ï¼Œç„¶åè®°ä½é‡è¦çš„å‘ç°"))
    
    # 2. AIå“åº”å¹¶å­˜å‚¨è®°å¿†
    messages.append(AIMessage(content="æˆ‘å°†åˆ†ææ•°æ®å¹¶è®°å½•é‡è¦å‘ç°"))
    
    # 3. è®°å¿†å­˜å‚¨äº‹ä»¶
    memory_event = EventMessageFactory.create_memory_store_event(
        memory_key="data_analysis_20241201",
        content="ç”¨æˆ·è¯·æ±‚æ•°æ®åˆ†æå¹¶è¦æ±‚è®°å½•é‡è¦å‘ç°"
    )
    messages.append(memory_event)
    
    # 4. å·¥å…·æ‰§è¡Œå¤±è´¥
    messages.append(ToolMessage(
        content="Error: æ•°æ®æ–‡ä»¶æ— æ³•è®¿é—®",
        tool_call_id="tool_123"
    ))
    
    # 5. è§¦å‘çº é”™
    correction_event = EventMessageFactory.create_correction_trigger_event(
        reason="æ•°æ®æ–‡ä»¶è®¿é—®å¤±è´¥",
        error_type="file_access_error"
    )
    messages.append(correction_event)
    
    # 6. çº é”™å°è¯•
    correction_attempt = EventMessageFactory.create_correction_attempt_event(
        correction_action="å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº",
        parent_event_id=correction_event.additional_kwargs["metadata"]["event_id"]
    )
    messages.append(correction_attempt)
    
    # 7. ç”¨æˆ·æ¾„æ¸…
    messages.append(HumanMessage(content="æˆ‘ä¹‹å‰æåˆ°çš„é‚£ä¸ªæ•°æ®æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"))
    
    # 8. è¯·æ±‚æ¾„æ¸…
    clarification_event = EventMessageFactory.create_clarification_request_event(
        question="æ‚¨æåˆ°çš„'é‚£ä¸ªæ•°æ®'å…·ä½“æŒ‡å“ªä¸ªæ•°æ®é›†ï¼Ÿ"
    )
    messages.append(clarification_event)
    
    return messages


if __name__ == "__main__":
    # åˆ›å»ºç¤ºä¾‹å¯¹è¯
    sample_messages = create_sample_conversation()
    
    # æ¼”ç¤ºçŠ¶æ€èšåˆ
    print("=== çŠ¶æ€èšåˆç¤ºä¾‹ ===")
    comprehensive_state = StateAggregator.get_comprehensive_state(sample_messages)
    print(f"æ€»æ¶ˆæ¯æ•°: {comprehensive_state['total_messages']}")
    print(f"è®°å¿†çŠ¶æ€: {comprehensive_state['memory']}")
    print(f"çº é”™çŠ¶æ€: {comprehensive_state['correction']}")
    print(f"æ¾„æ¸…çŠ¶æ€: {comprehensive_state['clarification']}")
    
    # æ¼”ç¤ºäº‹ä»¶æŸ¥è¯¢
    print("\n=== äº‹ä»¶æŸ¥è¯¢ç¤ºä¾‹ ===")
    example_event_query_usage(sample_messages)
    
    # æ¼”ç¤ºèŠ‚ç‚¹å¤„ç†
    print("\n=== èŠ‚ç‚¹å¤„ç†ç¤ºä¾‹ ===")
    initial_state = {"messages": sample_messages}
    
    # é€šè¿‡å„ä¸ªç¤ºä¾‹èŠ‚ç‚¹å¤„ç†
    state_after_correction = example_self_correction_node(initial_state)
    state_after_memory = example_memory_management_node(state_after_correction)
    state_after_analysis = example_state_analysis_node(state_after_memory)
    
    print(f"å¤„ç†åæ€»æ¶ˆæ¯æ•°: {len(state_after_analysis['messages'])}")
    print("æœ€æ–°æ¶ˆæ¯:")
    for msg in state_after_analysis['messages'][-3:]:
        print(f"  - {type(msg).__name__}: {msg.content}")