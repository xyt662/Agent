#!/usr/bin/env python3
"""
å‘é‡æ•°æ®åº“æ„å»ºè„šæœ¬

è¯¥è„šæœ¬è´Ÿè´£ï¼š
1. åŠ è½½åŸå§‹æ–‡æ¡£
2. åˆ‡åˆ†æ–‡æ¡£ä¸ºè¯­ä¹‰å—
3. ç”ŸæˆåµŒå…¥å‘é‡
4. å­˜å‚¨åˆ°ChromaDB
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from rag_agent.core.config import (
    get_vector_db_path,
    get_collection_name,
    get_project_root,
    DEFAULT_CHUNK_SIZE,
    DEFAULT_CHUNK_OVERLAP
)
from rag_agent.core.embedding_provider import get_embedding_model

def main():
    """æ„å»ºå‘é‡æ•°æ®åº“çš„ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“...")
    
    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“‹ åŠ è½½é…ç½®...")
        vector_store_path = get_vector_db_path()
        collection_name = get_collection_name()
        
        print(f"   å‘é‡æ•°æ®åº“è·¯å¾„: {vector_store_path}")
        print(f"   é›†åˆåç§°: {collection_name}")
        
        # 2. åŠ è½½åŸå§‹æ–‡æ¡£
        print("ğŸ“„ åŠ è½½åŸå§‹æ–‡æ¡£...")
        # ä½¿ç”¨get_project_root()è·å–é¡¹ç›®æ ¹ç›®å½•
        doc_path = get_project_root() / "data" / "raw" / "internal_docs.txt"
        if not doc_path.exists():
            raise FileNotFoundError(f"æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
            
        loader = TextLoader(str(doc_path), encoding='utf-8')
        documents = loader.load()
        print(f"   æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # 3. åˆ‡åˆ†æ–‡æ¡£
        print("âœ‚ï¸ åˆ‡åˆ†æ–‡æ¡£...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=DEFAULT_CHUNK_SIZE,
            chunk_overlap=DEFAULT_CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        
        chunks = text_splitter.split_documents(documents)
        print(f"   æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")
        
        # 4. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        print("ğŸ¤– åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")
        embeddings = get_embedding_model()
        print(f"   åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {embeddings.__class__.__name__}")
        
        # 5. åˆ›å»ºå¹¶æŒä¹…åŒ–ChromaDB
        print("ğŸ’¾ åˆ›å»ºå‘é‡æ•°æ®åº“...")
        
        # ç¡®ä¿å‘é‡å­˜å‚¨ç›®å½•å­˜åœ¨
        vector_store_dir = get_project_root() / vector_store_path
        vector_store_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºChromaDBå®ä¾‹
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=embeddings,
            collection_name=collection_name,
            persist_directory=str(vector_store_dir)
        )
        
        print(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºæˆåŠŸï¼")
        print(f"   å­˜å‚¨ä½ç½®: {vector_store_dir}")
        print(f"   é›†åˆåç§°: {collection_name}")
        print(f"   æ–‡æ¡£å—æ•°é‡: {len(chunks)}")
        
        # 6. æµ‹è¯•æ£€ç´¢åŠŸèƒ½
        print("ğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        test_results = retriever.invoke("LangGraphçš„æ ¸å¿ƒä¼˜åŠ¿")
        print(f"   æµ‹è¯•æŸ¥è¯¢è¿”å› {len(test_results)} ä¸ªç»“æœ")
        
        print("ğŸ‰ å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ„å»ºå‘é‡æ•°æ®åº“æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()